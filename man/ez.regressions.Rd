% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/stats.R
\name{ez.regressions}
\alias{ez.regressions}
\title{a series of simple regression, for many y and many x; in practice, in order to correctly calculate corrected p values, use many y and one x, or one y and many x}
\usage{
ez.regressions(df, y, x, covar = NULL, pthreshold = 0.05, showerror = F,
  print2screen = F, viewresults = F, plot = T, facet = "rows",
  pmethods = c("bonferroni", "fdr"), ...)
}
\arguments{
\item{df}{a data frame, if its column is factor, auto converts to numeric (internally call ez.2value(df))
\cr NA in df will be auto excluded in lm(), reflected by degree_of_freedom}

\item{y}{internally evaluated by eval('dplyr::select()'), a vector of outcome variables c('var1','var2'), or a single variable 'var1'}

\item{x}{internally evaluated by eval('dplyr::select()'), a vector of predictors, or a single predictor, (eg, names(select(beta,Gender:dmce)), but both mulitple/single x, only simple regression)}

\item{covar}{NULL=no covar, internally evaluated by eval('dplyr::select()'), a vector of covariates c('var1','var2'), or a single variable 'var1'}

\item{pthreshold}{default .05, print/output results whenever p < pthreshold, could be 1 then get all}

\item{showerror}{whether show error message when error occurs, default F}

\item{plot}{T/F, the black dash line is bonferroni p = 0.05, the grey black dash is uncorrected p = 0.05}

\item{facet}{one of 'cols', 'rows', 'wrap', valid only if plot=T}

\item{pmethods}{c('bonferroni','fdr'), type p.adjust.methods for all methods. even though pthreshold only shows a few sig results, this correction applies for all possible tests that have been done.}

\item{...}{dots passed to ez.2value(df,...)}
}
\value{
an invisible data frame with y,x,p,rp,beta,degree_of_freedom and print results out on screen; results can then be saved using ez.savex(results,'results.xlsx')
\cr beta: standardized coefficients or beta coefficients are the estimates resulting from a regression analysis that have been standardized 
\cr so that the variances of dependent and independent variables are 1.
\cr Therefore, standardized coefficients refer to how many standard deviations a dependent variable will change, 
\cr per standard deviation increase in the predictor variable. 
\cr For simple regression (1 y ~ 1 x), the value of the standardized coefficient (beta) equals the correlation coefficient (r) (beta=r).
\cr According to jerry testing, scale() or not for x,y or covar, does not change p values for predictors, although intercept would differ
\cr 
\cr degree_of_freedom: from F-statistic
\cr rp is robust regression (MASS::rlm) p value (see codes for more detail)
}
\description{
df=ez.2value(df,y,...), df[[xx]]=ez.2value(df[[xx]],...), lm(scale(df[[yy]])~scale(df[[xx]]))
}
\note{
To keep consistent with other R functions (eg, lm which converts numeric/non-numeric factor to values starting from 0), set start.at=0 in ez.2value(), then factor(1:2)->c(0,1), factor(c('girl','boy'))->c(1,0) # the level order is boy,girl
\cr in lm() the coding (0,1) vs.(1,2) does not affect slope, but changes intercept (but a coding from 1,2->1,3 would change slope--interval difference matters)
}
